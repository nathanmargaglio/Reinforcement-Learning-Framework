{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advantage Actor-Critic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of this code was adapted from this excellent article on Medium put out by Tensorflow:\n",
    "https://medium.com/tensorflow/deep-reinforcement-learning-playing-cartpole-through-asynchronous-advantage-actor-critic-a3c-7eab2eea5296\n",
    "\n",
    "Although they build an Asynchronous Advantage Actor Critic (A3C) model (while we're only building an A2C model), the code they wrote is so clean and intuitive that I was able to adapt it to the much simpler A2C model.  Even more, the article's utilization of Tensorflow's Eager Execution and Model Subclassing makes it possible to really explore how these models work and construct them from the ground up.  It's a pretty good read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import some useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script><script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window._Plotly) {require(['plotly'],function(plotly) {window._Plotly=plotly;});}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import gym\n",
    "import time\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "plotly.offline.init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we import `tensorflow` as `tf`.  We also import Tensorflow's Keras submodule so that we can build these models with ease using Tensorflow's Model Subclassing.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/models/Model\n",
    "\n",
    "We enable eager execution so that we can more readily experiment with the models we need.  TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, without building graphs: operations return concrete values instead of constructing a computational graph to run later.\n",
    "\n",
    "https://www.tensorflow.org/guide/eager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import layers\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.enable_eager_execution(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build an A2C model, we need to first build the critic model and the actor model.  The critic model is used to approximate the value of any state in an environment, while the actor is used to produce a probability of the actions we can take as the agent.  We can use the critic to determine which actions performed are favorible by calculating their advantage, which will then allow us to train our actor to make those favourable actions more likley."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Critic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we define the critic.  This model will recieve the observation as input and will return the value of the given state.\n",
    "<br>It's initialized with the size of the observation vector and the size of the action vector.\n",
    "<br>It's comprised of two hidden dense layers of size 128 with relu activations and a dense output layer of size 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CriticModel(keras.Model):\n",
    "    def __init__(self, observation_size, action_size):\n",
    "        super(CriticModel, self).__init__()\n",
    "        self.observation_size = observation_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.value_dense_1 = layers.Dense(128, activation='relu')\n",
    "        self.value_dense_2 = layers.Dense(128, activation='relu')\n",
    "        self.values = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_tensor = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        y = self.value_dense_1(input_tensor)\n",
    "        y = self.value_dense_2(y)\n",
    "        values = self.values(y)\n",
    "        return values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly test to see if our critic can learn a basic XOR dataset.  First, we create the XOR data and initialize our critic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "output_data = np.array([\n",
    "    [0],\n",
    "    [1],\n",
    "    [1],\n",
    "    [0]\n",
    "])\n",
    "\n",
    "critic = CriticModel(len(input_data[0]), len(output_data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we perform backpropagation to train the critic.  First, we pass the XOR input data through the critic to perform forward propagation, then we calculate the negative MSE of the actual XOR output data and the critic's output.  We perform both of these operations within the `GradientTape` context manager, which records operations for automatic differentiation.  \n",
    "We can then call the resulting `tape.gradient` method with the loss and weights we want to recieve the gradients for (i.e., the critic's trainable_weights).  This gives us back the gradients as tensors.  We can then iterate through the gradients and the critic's corresponding weights and add the gradients (multiplied by our learning rate `lr`) to the weights.\n",
    "\n",
    "This will complete one iteration of backpropagation for our critic.  We repeat this process for `epochs` iterations, which should result in fairly accurate results.\n",
    "\n",
    "https://www.tensorflow.org/api_docs/python/tf/GradientTape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(-0.06462556, shape=(), dtype=float32)\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n",
      "tf.Tensor(\n",
      "[[0.16791038]\n",
      " [0.886855  ]\n",
      " [0.8878074 ]\n",
      " [0.10508424]], shape=(4, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    with tf.GradientTape() as tape:\n",
    "        values = critic(input_data)\n",
    "        critic_loss = -tf.reduce_sum((output_data - values)**2)\n",
    "\n",
    "    critic_grads = tape.gradient(critic_loss, critic.trainable_weights)\n",
    "    for w, g in zip(critic.trainable_weights, critic_grads):\n",
    "        w.assign_add(lr * g)\n",
    "        \n",
    "print(critic_loss)\n",
    "print(output_data)\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The critic will be tasked with learning the value function for our environment.  This means that we will train the critic with the discounted future rewards calculated for every episode, so that we can readily approximate the the value of any given state in our environment.  We will then use this value to train the actor model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the actor.  This model will recieve the observation as input and will return the probability distribution of the actions for the given state.\n",
    "<br>It's initialized with the size of the observation vector and the size of the action vector.\n",
    "<br>It's comprised of two hidden dense layers of size 128 with relu activations and a dense output layer of size `action_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorModel(keras.Model):\n",
    "    def __init__(self, observation_size, action_size):\n",
    "        super(ActorModel, self).__init__()\n",
    "        self.observation_size = observation_size\n",
    "        self.action_size = action_size\n",
    "        \n",
    "        self.policy_dense_1 = layers.Dense(128, activation='relu')\n",
    "        self.policy_dense_2 = layers.Dense(128, activation='relu')\n",
    "        self.policy_logits = layers.Dense(action_size)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        input_tensor = tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
    "        x = self.policy_dense_1(input_tensor)\n",
    "        x = self.policy_dense_2(x)\n",
    "        logits = self.policy_logits(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now quickly test the model.  We are going to provide pseudo advantage values in order to see if we can train our actor to perform specific actions at specific states.\n",
    "\n",
    "The observation data our agent will receive will be simple: one of either `[1, 0, 0]`, `[0, 1, 0]`, or `[0, 0, 1]`.  The agent will be given an action size of 3, so that it will produce a probability over 3 actions.\n",
    "\n",
    "We will reward the actor with +1 if it's chosen action matches the observation and -1 otherwise (e.g., if the observation is `[1, 0, 0]`, then the actor recieves +1 if it chooses the 0th action)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_actor_test(state, reward=1):\n",
    "    print(state)\n",
    "    observations = [[1,0,0], [0,1,0], [0,0,1]]\n",
    "    lr = 0.01\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = actor([observations[state]])\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        action = np.random.choice(3, p=probs.numpy()[0])\n",
    "        if action == np.argmax(observations[state]):\n",
    "            adv = reward\n",
    "        else:\n",
    "            adv = -reward\n",
    "        mask = np.zeros(3)\n",
    "        mask[action] = adv\n",
    "        actor_loss = tf.log(probs + 1e-10)*mask\n",
    "\n",
    "    actor_grads = tape.gradient(actor_loss, actor.trainable_weights)\n",
    "\n",
    "    for w, ag in zip(actor.trainable_weights, actor_grads):\n",
    "        w.assign_add(lr*ag)\n",
    "\n",
    "    # Visualization\n",
    "    for i, obs in enumerate(observations):\n",
    "        logits = actor([obs])\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        fig.data[i]['y'] = np.array(probs.numpy()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "actor = ActorModel(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b73e02aa4b4f49c3970daa9377ffe44c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureWidget({\n",
       "    'data': [{'name': 'State 0',\n",
       "              'type': 'bar',\n",
       "              'uid': 'e60da850-14…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "layout = go.Layout(\n",
    "    title = \"Action Probabilites\",\n",
    "    xaxis1 = dict(\n",
    "        domain=[0, 0.32],\n",
    "        dtick=1,\n",
    "    ),\n",
    "    yaxis = dict(\n",
    "        anchor='x1',\n",
    "        range=[0,1]\n",
    "    ),\n",
    "    xaxis2 = dict(\n",
    "        domain=[0.35, 0.65],\n",
    "        dtick=1,\n",
    "    ),\n",
    "    yaxis2 = dict(\n",
    "        anchor='x2',\n",
    "        range=[0,1]\n",
    "    ),\n",
    "    xaxis3 = dict(\n",
    "        domain=[0.70, 1],\n",
    "        dtick=1,\n",
    "    ),\n",
    "    yaxis3 = dict(\n",
    "        anchor='x3',\n",
    "        range=[0,1]\n",
    "    ),\n",
    ")\n",
    "data = [\n",
    "    go.Bar(y=np.zeros(3), xaxis='x1', yaxis='y1', name=\"State 0\"),\n",
    "    go.Bar(y=np.zeros(3), xaxis='x2', yaxis='y2', name=\"State 1\"),\n",
    "    go.Bar(y=np.zeros(3), xaxis='x3', yaxis='y3', name=\"State 2\")\n",
    "]\n",
    "fig = go.FigureWidget(data=data, layout=layout)\n",
    "fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09421fb2f95b4ec19e8cd00598b79192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Button(description='State 0', style=ButtonStyle()), Button(description='State 1', style=ButtonSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "buttons = []\n",
    "reward = 10\n",
    "for state in range(3):\n",
    "    button = widgets.Button(\n",
    "        description=f'State {state}',\n",
    "        state=state\n",
    "    )\n",
    "    click_function = lambda state: lambda b: run_actor_test(state, reward)\n",
    "    button.on_click(click_function(state))\n",
    "    buttons.append(button)\n",
    "\n",
    "widgets.Box(buttons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = np.array([\n",
    "    [0, 0],\n",
    "    [0, 1],\n",
    "    [1, 0],\n",
    "    [1, 1]\n",
    "])\n",
    "\n",
    "correct_action = np.array([\n",
    "    [1, 0],\n",
    "    [0, 1],\n",
    "    [0, 1],\n",
    "    [1, 0]\n",
    "])\n",
    "\n",
    "class XOREnv:\n",
    "    def __init__(self, timesteps=10):\n",
    "        self.action_space = gym.spaces.MultiBinary(1)\n",
    "        self.observation_space = gym.spaces.Discrete(2)\n",
    "        \n",
    "        self.observations = np.array([\n",
    "            [0, 0],\n",
    "            [0, 1],\n",
    "            [1, 0],\n",
    "            [1, 1]\n",
    "        ])\n",
    "        \n",
    "        self.actions = np.array([\n",
    "            [1, 0],\n",
    "            [0, 1],\n",
    "            [0, 1],\n",
    "            [1, 0]\n",
    "        ])\n",
    "        \n",
    "        self.timesteps = timesteps\n",
    "\n",
    "    def reset(self):\n",
    "        self.timestep = 0\n",
    "        self.state = np.random.choice(len(self.actions))\n",
    "        return self.observations[self.state]\n",
    "    \n",
    "    def step(self, action):\n",
    "        if action == np.argmax(self.actions[self.state]):\n",
    "            reward = 1\n",
    "        else:\n",
    "            reward = -1\n",
    "            \n",
    "        self.state = np.random.choice(len(self.actions))\n",
    "        \n",
    "        self.timestep += 1\n",
    "        if self.timestep > self.timesteps:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "            \n",
    "        if self.timestep + 1 > self.timesteps:\n",
    "            last_run = True\n",
    "        else:\n",
    "            last_run = False\n",
    "            \n",
    "        return self.observations[self.state], reward, done, { \"last_run\": last_run }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomAgent:\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        \n",
    "    def step(self, observation):\n",
    "        return np.random.choice(self.env.action_space.n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:root:         step: 0\n",
      "DEBUG:root:       action: 0\n",
      "DEBUG:root:     next_obs: [1 0]\n",
      "DEBUG:root:       reward: 1\n",
      "DEBUG:root:         done: False\n",
      "DEBUG:root:         info: {'last_run': False}\n",
      "DEBUG:root: total_reward: 1\n",
      "DEBUG:root:          ...\n",
      "\n",
      "INFO:root: Total Reward: 1\n"
     ]
    }
   ],
   "source": [
    "env = XOREnv()\n",
    "agent = RandomAgent(env)\n",
    "\n",
    "obs = agent.env.reset()\n",
    "done = False\n",
    "step = 0\n",
    "rewards = []\n",
    "while not done:\n",
    "    print(f\"{'step':>13}: {step}\")\n",
    "    action = agent.step(obs)\n",
    "    print(f\"{'action':>13}: {action}\")\n",
    "    \n",
    "    next_obs, reward, done, info = agent.env.step(action)\n",
    "    print(f\"{'next_obs':>13}: {next_obs}\")\n",
    "    print(f\"{'reward':>13}: {reward}\")\n",
    "    print(f\"{'done':>13}: {done}\")\n",
    "    print(f\"{'info':>13}: {info}\")\n",
    "    \n",
    "    step += 1\n",
    "    rewards.append(reward)\n",
    "    total_reward = np.sum(rewards)\n",
    "    print(f\"{'total_reward':>13}: {total_reward}\")\n",
    "    print(f\"{'...':>13}\\n\")\n",
    "    \n",
    "print(f\" Total Reward: {np.sum(rewards)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActorCriticModel(keras.Model):\n",
    "    def __init__(self, observation_size, action_size):\n",
    "        super(ActorCriticModel, self).__init__()\n",
    "        self.observation_size = observation_size\n",
    "        self.action_size = action_size\n",
    "        self.actor = ActorModel(observation_size, action_size)\n",
    "        self.critic = CriticModel(observation_size, action_size)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        return self.actor(inputs), self.critic(inputs)\n",
    "\n",
    "class HyperParameters:\n",
    "    def __init__(self, **kw):\n",
    "        self.gamma = 0.99\n",
    "        self.vf_coef = 0.5\n",
    "        self.ent_coef = 0.01\n",
    "        self.lr = 0.001\n",
    "        self.__dict__.update(kw)\n",
    "        \n",
    "def moving_average(a, n=3) :\n",
    "    ret = np.cumsum(a, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    return ret[n - 1:] / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(a2c, observations, actions, discounted_rewards, hyperparameters, verbose=False, normalize_discounted_rewards=True, *args, **kargs):\n",
    "    hp = hyperparameters\n",
    "    \n",
    "    logits, values = a2c(tf.convert_to_tensor(observations, dtype=tf.float32))\n",
    "    values = tf.squeeze(values)\n",
    "\n",
    "    if normalize_discounted_rewards:\n",
    "        discounted_rewards -= np.mean(discounted_rewards)\n",
    "        discounted_rewards /= np.std(discounted_rewards)\n",
    "\n",
    "    discounted_rewards = tf.convert_to_tensor(np.array(discounted_rewards), dtype=tf.float32)\n",
    "    advantages =  tf.stop_gradient(discounted_rewards) - values\n",
    "\n",
    "    critic_loss = advantages ** 2\n",
    "\n",
    "    policy = tf.nn.softmax(logits)\n",
    "    entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=policy, logits=logits)\n",
    "\n",
    "    actor_loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=actions, logits=logits)\n",
    "    actor_loss *= tf.stop_gradient(advantages)\n",
    "    actor_loss -= hp.ent_coef * entropy\n",
    "\n",
    "    total_loss = tf.reduce_mean(hp.vf_coef * critic_loss + actor_loss)\n",
    "\n",
    "    if verbose:\n",
    "        variables = dir()[:]\n",
    "        for key in variables:\n",
    "            print(key)\n",
    "            print(locals()[key])\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(env, a2c, verbose=False, *args, **kargs):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    rewards = []\n",
    "    actions = []\n",
    "    observations = []\n",
    "        \n",
    "    while not done:\n",
    "        logits, _ = a2c(tf.convert_to_tensor(obs[None, :], dtype=tf.float32))\n",
    "        probs = tf.nn.softmax(logits)\n",
    "        action = np.random.choice(env.action_space.n, p=probs.numpy()[0])\n",
    "\n",
    "        next_obs, reward, done, info = env.step(action)\n",
    "        \n",
    "        if done:\n",
    "            reward = -1\n",
    "        \n",
    "        observations.append(obs)\n",
    "        actions.append(action)\n",
    "        rewards.append(reward)\n",
    "        \n",
    "        obs = next_obs\n",
    "        total_reward = np.sum(rewards)\n",
    "        \n",
    "        if verbose:\n",
    "            variables = dir()[:]\n",
    "            for key in variables:\n",
    "                print(key)\n",
    "                print(locals()[key])\n",
    "            \n",
    "        if done:\n",
    "            return observations, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_discounted_rewards(rewards, gamma=0.99):\n",
    "    discounted_rewards = []\n",
    "    reward_sum = 0\n",
    "    for reward in rewards[::-1]:\n",
    "        reward_sum = reward + gamma * reward_sum\n",
    "        discounted_rewards.append(reward_sum)\n",
    "    discounted_rewards.reverse()\n",
    "    return discounted_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(a2c, observations, actions, discounted_rewards, hyperparameters, *args, **kargs):\n",
    "    opt = tf.train.AdamOptimizer(hp.lr, use_locking=True)\n",
    "    with tf.GradientTape() as tape:\n",
    "        total_loss = loss(a2c, observations, actions, discounted_rewards, hyperparameters=hp, **kargs)\n",
    "\n",
    "    grads = tape.gradient(total_loss, a2c.trainable_weights)\n",
    "    opt.apply_gradients(zip(grads, a2c.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: id=88, shape=(1, 2), dtype=float32, numpy=array([[ 0.03009   , -0.01452742]], dtype=float32)>,\n",
       " <tf.Tensor: id=174, shape=(1, 1), dtype=float32, numpy=array([[-0.01758317]], dtype=float32)>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "#env = gym.make('LunarLander-v2')\n",
    "a2c = ActorCriticModel(env.observation_space.shape[0], env.action_space.n)\n",
    "a2c(tf.convert_to_tensor(np.random.random((1, a2c.state_size)), dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 26 (0.403s): 18.5\n",
      "Ep 41 (1.129s): 39.0\n",
      "Ep 52 (1.854s): 51.1\n",
      "Ep 56 (2.565s): 81.4\n",
      "Ep 62 (3.290s): 101.8\n",
      "Ep 66 (4.034s): 105.0\n",
      "Ep 71 (4.799s): 118.0\n",
      "Ep 76 (5.566s): 106.6\n",
      "Ep 79 (6.384s): 129.6\n",
      "Ep 86 (7.184s): 114.9\n",
      "Ep 90 (8.103s): 121.2\n",
      "Ep 93 (8.942s): 159.0\n",
      "Ep 96 (9.788s): 188.9\n",
      "10.54092526435852\n"
     ]
    }
   ],
   "source": [
    "hp = HyperParameters(gamma = 0.99, vf_coef = 0.5, ent_coef = 0.001, lr = 0.001)\n",
    "\n",
    "start_time = time.time()\n",
    "batch = {\n",
    "    \"observations\": [],\n",
    "    \"actions\": [],\n",
    "    \"discounted_rewards\": []\n",
    "}\n",
    "\n",
    "ep_rewards = []\n",
    "episodes = 100\n",
    "episode = 0\n",
    "epochs = 8\n",
    "batch_size = 512\n",
    "while episode < episodes:\n",
    "    observations, actions, rewards = run(env, a2c, verbose=0)\n",
    "    ep_rewards.append(np.sum(rewards))\n",
    "    \n",
    "    # Calculate True Discounted Rewards\n",
    "    discounted_rewards = get_discounted_rewards(rewards, hp.gamma)\n",
    "    \n",
    "    batch['observations'] += observations\n",
    "    batch['actions'] += actions\n",
    "    batch['discounted_rewards'] += discounted_rewards\n",
    "\n",
    "    if len(batch['observations']) >= batch_size:\n",
    "        print(f\"Ep {episode} ({time.time() - start_time:.3f}s): {np.mean(ep_rewards[-10:])}\")\n",
    "        for epoch in range(epochs):\n",
    "            learn(a2c, hyperparameters=hp, lock_actor=True, **batch)\n",
    "        batch = {\n",
    "            \"observations\": [],\n",
    "            \"actions\": [],\n",
    "            \"discounted_rewards\": []\n",
    "        }\n",
    "    episode += 1\n",
    "    \n",
    "end_time = time.time()\n",
    "print(end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2c\n",
      "<__main__.ActorCriticModel object at 0x7f67c0609c50>\n",
      "actions\n",
      "[0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1]\n",
      "actor_loss\n",
      "tf.Tensor(\n",
      "[ 1.60148993e-01  4.41398658e-02  1.43281743e-01  4.70659398e-02\n",
      "  1.32774949e-01  4.90165502e-02  5.98091424e-01  1.81604338e+00\n",
      "  1.12967473e-02  2.99371146e-02  8.44361782e-02  6.28321245e-02\n",
      "  7.17442557e-02  7.63893276e-02  6.23220690e-02  6.97361112e-01\n",
      "  1.21585354e-02  1.09329566e-01  5.41375987e-02  1.19269513e-01\n",
      "  1.04863775e+00  1.74634736e-02  1.08337033e+00  1.53384432e-02\n",
      "  3.69983725e-02  3.64243597e-01  1.89453121e-02  3.20768416e-01\n",
      "  2.24381555e-02  2.95125604e-01  2.51078140e-02  2.85125345e-01\n",
      "  1.79093409e+00  4.05341666e-03  2.63197813e-02  3.71232897e-01\n",
      "  2.34986581e-02  2.54884958e-01  1.33958292e+00  1.43096466e-02\n",
      "  4.06898223e-02  1.63555115e-01  4.11815122e-02  1.42746732e-01\n",
      "  4.15079519e-02  1.25574574e-01  4.17063683e-02  1.11014806e-01\n",
      "  4.17615958e-02  9.82630923e-02  4.17897925e-02  8.70099664e-02\n",
      "  4.18043137e-02  6.24926031e-01  9.46499128e-03  6.93263933e-02\n",
      "  5.19042276e-02  5.54366373e-02  5.79399727e-02  4.41303030e-02\n",
      "  6.67012110e-02  9.41788971e-01  6.00277539e-03  2.93804910e-02\n",
      "  1.27289206e-01  2.32458562e-02  1.98463336e-01  6.53811693e-01\n",
      "  1.38775576e-02  3.61308828e-02  2.01282129e-01  1.10492222e-02\n",
      "  5.33278100e-02  4.31695469e-02  3.39506269e-02  2.24286333e-01\n",
      "  1.61934700e-02  3.01299561e-02  1.26193166e-02  2.52131820e-02\n",
      "  9.31067113e-03  1.91689171e-02  7.30233733e-03  2.88097169e-02\n",
      "  1.08415410e-02 -9.60764196e-03  1.13129251e-01  3.08255246e-03\n",
      "  3.32320784e-03 -2.12156307e-02  3.36816628e-03 -5.57069182e-02\n",
      "  3.96640506e-04 -4.52187322e-02 -7.62179261e-03 -5.48376106e-02\n",
      " -1.58410259e-02 -6.34391084e-02 -2.52367873e-02 -7.15929717e-02\n",
      " -3.53456698e-02 -8.26484412e-02 -4.57039922e-02 -9.71033350e-02\n",
      " -5.55638596e-02 -3.54794204e-01 -1.37279136e-02 -1.25197023e-01\n",
      " -3.11312705e-01 -8.00837390e-03 -8.02642852e-02 -1.92578018e-01\n",
      " -8.20526183e-02 -2.50470668e-01 -7.96498805e-02 -3.31338525e-01\n",
      " -7.34390840e-02 -4.42027152e-01 -8.90584469e-01 -8.87777746e-01\n",
      " -7.48996972e-04 -6.02797559e-03 -2.94442642e-02 -1.34347156e-01\n",
      " -4.53241765e-01 -8.08101594e-02 -8.95507276e-01 -4.58633304e-02\n",
      " -1.46485710e+00 -2.63248328e-02 -1.05063714e-01 -9.22828555e-01\n",
      " -6.62137344e-02 -1.09483075e+00 -3.62349600e-02 -2.10493267e-01\n",
      " -2.61152178e-01 -9.68608707e-02 -1.02774370e+00 -4.78609242e-02\n",
      " -5.96967280e-01 -7.91839659e-02 -3.36577296e-01 -1.28641397e-01\n",
      " -1.69648099e+00 -1.82757545e-02 -1.11763127e-01 -1.20272529e+00\n",
      " -2.60836612e-02 -4.82043505e-01 -4.63845059e-02 -6.59467578e-01\n",
      " -3.45602073e-02 -8.78852785e-01 -2.67500449e-02 -3.39980811e-01\n",
      " -1.05468981e-01 -2.45651767e-01 -1.37970179e-01 -1.86579794e-01\n",
      " -1.70839891e-01 -1.49487555e-01 -2.05390096e-01 -1.25895545e-01\n",
      " -1.38095033e+00 -1.40778897e-02 -2.44817585e-01 -1.12591676e-01\n",
      " -2.46748134e-01 -1.18041463e-01 -2.40666360e-01 -1.28714100e-01\n",
      " -2.28016928e-01 -1.45054653e-01 -2.09825471e-01 -1.69254154e-01\n",
      " -1.87375262e-01 -2.03972444e-01 -1.61837846e-01 -2.55188137e-01\n",
      " -1.35153890e-01 -1.47585654e+00 -2.48047505e-02 -1.32903171e+00\n",
      " -2.90571637e-02 -5.27420521e-01 -7.91135207e-02 -6.54638171e-01\n",
      " -6.19872920e-02 -8.37838650e-01 -5.72974645e-02 -6.78191841e-01\n",
      " -3.89760232e+00 -1.62267797e-02 -1.05976760e-01 -4.74574834e-01\n",
      " -1.38962463e-01 -1.93440139e+00 -2.08207984e-02 -3.02310765e-01], shape=(200,), dtype=float32)\n",
      "advantages\n",
      "tf.Tensor(\n",
      "[ 0.44596344  0.54200405  0.44625574  0.53810793  0.44635254  0.5357097\n",
      "  0.44496936  0.6380058   0.8215588   0.61744666  0.41645485  0.44288385\n",
      "  0.43076974  0.43911368  0.44410908  0.43723983  0.6028276   0.45871973\n",
      "  0.47054863  0.454185    0.4728554   0.66749954  0.4638554   0.6652067\n",
      "  0.47056818  0.39735502  0.53216475  0.41803235  0.55248475  0.43537146\n",
      "  0.57052064  0.4491676   0.5873257   0.76312923  0.6340498   0.4972798\n",
      "  0.6525356   0.509593    0.5334852   0.66168594  0.48169795  0.44500023\n",
      "  0.4560517   0.43283233  0.43181044  0.422022    0.40808398  0.41196373\n",
      "  0.3844852   0.40206793  0.3611326   0.39200374  0.33829176  0.38197577\n",
      "  0.5541377   0.41037688  0.31989494  0.40367243  0.29936573  0.3988851\n",
      "  0.28251374  0.3952753   0.5762877   0.43830654  0.2886346   0.45097896\n",
      "  0.2863295   0.31641263  0.4174637   0.25099736  0.1853449   0.37830648\n",
      "  0.2031121   0.20219752  0.18348432  0.16680223  0.24778575  0.10888433\n",
      "  0.11960968  0.08335027  0.10807213  0.05963987  0.10062471  0.03745556\n",
      "  0.11461672 -0.00531441  0.04711121  0.25689426  0.07584724 -0.02097946\n",
      "  0.04182848 -0.06091794  0.04218501 -0.07573175 -0.00934058 -0.10874829\n",
      " -0.03750953 -0.14236358 -0.0665271  -0.17516354 -0.09677628 -0.2126972\n",
      " -0.12881796 -0.25401837 -0.16268891 -0.29591575 -0.22609991 -0.32478344\n",
      " -0.22741547 -0.07729048 -0.2709286  -0.42996532 -0.31419635 -0.48392904\n",
      " -0.35640514 -0.5375294  -0.39715374 -0.58996403 -0.43317148 -0.24896844\n",
      " -0.06327467 -0.2751979  -0.47828475 -0.7021014  -0.8867597  -0.72119004\n",
      " -0.9144831  -0.7069311  -0.920177   -0.6837083  -0.8994305  -1.0505288\n",
      " -1.039139   -1.0542121  -0.8482895  -1.0334439  -1.067878   -0.99695766\n",
      " -1.0530113  -0.99982226 -1.0252931  -0.9883847  -1.0002136  -0.9739239\n",
      " -0.9756284  -0.8089806  -0.9641447  -0.9675155  -0.9021156  -0.9398179\n",
      " -0.8998535  -0.9381095  -0.882226   -0.9391124  -0.86586326 -0.9388941\n",
      " -0.90986603 -0.9250961  -0.90657514 -0.9194537  -0.9077473  -0.92127824\n",
      " -0.9118988  -0.92822415 -0.9178432  -0.82980067 -0.90826106 -0.9379933\n",
      " -0.9232544  -0.9576268  -0.9376439  -0.98157257 -0.9512162  -1.0047102\n",
      " -0.9642354  -1.0258844  -0.97666    -1.0443506  -0.99171376 -1.0642793\n",
      " -1.007443   -1.0862149  -1.1533813  -1.1295685  -1.2069982  -1.1724377\n",
      " -1.0933957  -1.188379   -1.1033189  -1.2041831  -1.3068429  -1.2404664\n",
      " -1.348273   -1.3918118  -1.411948   -1.339136   -1.4544419  -1.3767366\n",
      " -1.2874331  -1.3883877 ], shape=(200,), dtype=float32)\n",
      "args\n",
      "()\n",
      "critic_loss\n",
      "tf.Tensor(\n",
      "[1.9888338e-01 2.9376835e-01 1.9914418e-01 2.8956014e-01 1.9923058e-01\n",
      " 2.8698486e-01 1.9799772e-01 4.0705138e-01 6.7495883e-01 3.8124037e-01\n",
      " 1.7343464e-01 1.9614610e-01 1.8556258e-01 1.9282080e-01 1.9723289e-01\n",
      " 1.9117866e-01 3.6340111e-01 2.1042380e-01 2.2141601e-01 2.0628400e-01\n",
      " 2.2359222e-01 4.4555563e-01 2.1516180e-01 4.4249991e-01 2.2143440e-01\n",
      " 1.5789101e-01 2.8319931e-01 1.7475103e-01 3.0523941e-01 1.8954828e-01\n",
      " 3.2549378e-01 2.0175153e-01 3.4495148e-01 5.8236623e-01 4.0201908e-01\n",
      " 2.4728718e-01 4.2580271e-01 2.5968504e-01 2.8460646e-01 4.3782827e-01\n",
      " 2.3203291e-01 1.9802521e-01 2.0798315e-01 1.8734382e-01 1.8646024e-01\n",
      " 1.7810260e-01 1.6653252e-01 1.6971411e-01 1.4782885e-01 1.6165861e-01\n",
      " 1.3041675e-01 1.5366693e-01 1.1444132e-01 1.4590548e-01 3.0706862e-01\n",
      " 1.6840918e-01 1.0233277e-01 1.6295142e-01 8.9619845e-02 1.5910931e-01\n",
      " 7.9814009e-02 1.5624255e-01 3.3210748e-01 1.9211262e-01 8.3309926e-02\n",
      " 2.0338203e-01 8.1984580e-02 1.0011696e-01 1.7427592e-01 6.2999681e-02\n",
      " 3.4352731e-02 1.4311580e-01 4.1254528e-02 4.0883835e-02 3.3666492e-02\n",
      " 2.7822983e-02 6.1397776e-02 1.1855799e-02 1.4306476e-02 6.9472678e-03\n",
      " 1.1679585e-02 3.5569142e-03 1.0125332e-02 1.4029189e-03 1.3136992e-02\n",
      " 2.8242950e-05 2.2194663e-03 6.5994658e-02 5.7528042e-03 4.4013793e-04\n",
      " 1.7496221e-03 3.7109957e-03 1.7795749e-03 5.7352982e-03 8.7246510e-05\n",
      " 1.1826189e-02 1.4069650e-03 2.0267386e-02 4.4258549e-03 3.0682264e-02\n",
      " 9.3656471e-03 4.5240097e-02 1.6594067e-02 6.4525336e-02 2.6467681e-02\n",
      " 8.7566130e-02 5.1121168e-02 1.0548429e-01 5.1717792e-02 5.9738187e-03\n",
      " 7.3402300e-02 1.8487015e-01 9.8719344e-02 2.3418730e-01 1.2702462e-01\n",
      " 2.8893787e-01 1.5773110e-01 3.4805757e-01 1.8763754e-01 6.1985284e-02\n",
      " 4.0036836e-03 7.5733878e-02 2.2875631e-01 4.9294636e-01 7.8634280e-01\n",
      " 5.2011508e-01 8.3627927e-01 4.9975163e-01 8.4672570e-01 4.6745706e-01\n",
      " 8.0897522e-01 1.1036106e+00 1.0798100e+00 1.1113632e+00 7.1959507e-01\n",
      " 1.0680063e+00 1.1403635e+00 9.9392450e-01 1.1088328e+00 9.9964452e-01\n",
      " 1.0512259e+00 9.7690433e-01 1.0004274e+00 9.4852781e-01 9.5185065e-01\n",
      " 6.5444958e-01 9.2957503e-01 9.3608630e-01 8.1381255e-01 8.8325769e-01\n",
      " 8.0973637e-01 8.8004941e-01 7.7832270e-01 8.8193214e-01 7.4971920e-01\n",
      " 8.8152212e-01 8.2785618e-01 8.5580277e-01 8.2187843e-01 8.4539509e-01\n",
      " 8.2400519e-01 8.4875357e-01 8.3155936e-01 8.6160004e-01 8.4243619e-01\n",
      " 6.8856913e-01 8.2493812e-01 8.7983137e-01 8.5239863e-01 9.1704911e-01\n",
      " 8.7917602e-01 9.6348470e-01 9.0481228e-01 1.0094426e+00 9.2974997e-01\n",
      " 1.0524389e+00 9.5386475e-01 1.0906683e+00 9.8349613e-01 1.1326904e+00\n",
      " 1.0149413e+00 1.1798629e+00 1.3302885e+00 1.2759248e+00 1.4568447e+00\n",
      " 1.3746101e+00 1.1955142e+00 1.4122448e+00 1.2173127e+00 1.4500570e+00\n",
      " 1.7078384e+00 1.5387567e+00 1.8178401e+00 1.9371402e+00 1.9935971e+00\n",
      " 1.7932853e+00 2.1154013e+00 1.8954037e+00 1.6574842e+00 1.9276203e+00], shape=(200,), dtype=float32)\n",
      "discounted_rewards\n",
      "tf.Tensor(\n",
      "[ 1.2229469   1.2173308   1.2116581   1.205928    1.20014     1.1942936\n",
      "  1.1883881   1.182423    1.1763977   1.1703115   1.1641637   1.1579539\n",
      "  1.1516813   1.1453454   1.1389456   1.132481    1.1259512   1.1193553\n",
      "  1.112693    1.1059632   1.0991656   1.0922991   1.0853634   1.0783577\n",
      "  1.0712811   1.064133    1.0569129   1.0496197   1.0422529   1.0348116\n",
      "  1.0272952   1.0197029   1.0120339   1.0042874   0.9964627   0.98855895\n",
      "  0.9805753   0.97251105  0.96436536  0.9561374   0.9478263   0.93943125\n",
      "  0.9309514   0.92238593  0.9137339   0.9049945   0.8961668   0.88724995\n",
      "  0.878243    0.86914515  0.8599554   0.8506727   0.8412963   0.8318252\n",
      "  0.8222585   0.81259507  0.80283403  0.7929744   0.78301525  0.7729554\n",
      "  0.762794    0.75253     0.7421622   0.73168975  0.72111154  0.71042645\n",
      "  0.6996334   0.6887314   0.67771924  0.6665958   0.6553601   0.64401084\n",
      "  0.63254696  0.62096727  0.60927063  0.5974558   0.5855217   0.573467\n",
      "  0.56129056  0.5489911   0.53656745  0.5240182   0.51134235  0.49853835\n",
      "  0.48560506  0.47254112  0.45934522  0.446016    0.4325522   0.41895235\n",
      "  0.40521514  0.39133918  0.37732306  0.36316538  0.34886464  0.3344195\n",
      "  0.31982842  0.30508998  0.29020265  0.27516493  0.25997534  0.24463232\n",
      "  0.2291343   0.21347974  0.19766706  0.18169466  0.1655609   0.1492642\n",
      "  0.13280287  0.11617527  0.09937971  0.08241451  0.06527793  0.04796826\n",
      "  0.03048374  0.01282261 -0.00501691 -0.02303663 -0.04123837 -0.05962396\n",
      " -0.07819527 -0.09695416 -0.11590254 -0.13504232 -0.15437542 -0.17390382\n",
      " -0.19362947 -0.21355437 -0.23368052 -0.25400996 -0.27454478 -0.295287\n",
      " -0.31623873 -0.3374021  -0.35877925 -0.38037235 -0.40218353 -0.42421505\n",
      " -0.44646907 -0.46894792 -0.4916538  -0.5145891  -0.53775597 -0.56115687\n",
      " -0.58479416 -0.60867023 -0.63278747 -0.6571483  -0.6817552  -0.7066107\n",
      " -0.73171717 -0.75707734 -0.7826936  -0.80856866 -0.83470505 -0.86110544\n",
      " -0.88777256 -0.914709   -0.94191754 -0.9694009  -0.99716187 -1.0252032\n",
      " -1.0535278  -1.0821387  -1.1110383  -1.1402301  -1.1697165  -1.1995009\n",
      " -1.2295861  -1.2599752  -1.2906712  -1.3216774  -1.3529967  -1.3846323\n",
      " -1.4165876  -1.4488657  -1.4814698  -1.5144031  -1.5476692  -1.5812712\n",
      " -1.6152127  -1.649497   -1.6841276  -1.7191081  -1.7544419  -1.7901325\n",
      " -1.8261837  -1.862599   -1.8993822  -1.9365369  -1.974067   -2.011976\n",
      " -2.0502682  -2.0889468  -2.1280165  -2.1674807  -2.2073433  -2.247609\n",
      " -2.288281   -2.329364  ], shape=(200,), dtype=float32)\n",
      "entropy\n",
      "tf.Tensor(\n",
      "[0.62017226 0.28619164 0.596941   0.29984805 0.5801443  0.30869627\n",
      " 0.5703709  0.22101039 0.07607348 0.19970621 0.49065936 0.40527302\n",
      " 0.4431067  0.45317954 0.4027325  0.5012502  0.10444506 0.5282771\n",
      " 0.35772076 0.55134565 0.34247527 0.1265411  0.3164211  0.11500491\n",
      " 0.28151318 0.67014116 0.1611885  0.6893854  0.1769607  0.693147\n",
      " 0.18713409 0.6921838  0.19030288 0.03544356 0.17847107 0.6910291\n",
      " 0.16070485 0.6736304  0.28062367 0.10954294 0.29461387 0.6247542\n",
      " 0.3082802  0.60293543 0.32152733 0.5807743  0.33492613 0.5584631\n",
      " 0.3486506  0.53585833 0.36330342 0.5132573  0.37888014 0.48949885\n",
      " 0.09243639 0.44720086 0.442055   0.39929193 0.48507506 0.3519116\n",
      " 0.53324205 0.306216   0.06249526 0.25426945 0.65956265 0.21211714\n",
      " 0.6928618  0.37706184 0.15601595 0.4199887  0.63149893 0.14316925\n",
      " 0.5645174  0.5174581  0.4872388  0.56448346 0.26158488 0.5948747\n",
      " 0.38358238 0.6224215  0.35027125 0.6470951  0.32388917 0.6677227\n",
      " 0.36436623 0.67785275 0.2912119  0.0774766  0.2696275  0.69307125\n",
      " 0.46190274 0.68786144 0.2355941  0.67239285 0.52854604 0.65266204\n",
      " 0.5517649  0.6344489  0.5674992  0.6203318  0.57654214 0.6126847\n",
      " 0.5796498  0.61175704 0.5768604  0.6173785  0.20011233 0.61654925\n",
      " 0.5739803  0.25037512 0.5523309  0.64825964 0.5229676  0.67123526\n",
      " 0.48521796 0.68875253 0.4389822  0.6922053  0.38469347 0.12920906\n",
      " 0.03674142 0.09174167 0.21435075 0.45397735 0.67119575 0.3292607\n",
      " 0.663239   0.22644477 0.50679034 0.1537171  0.33993745 0.67968\n",
      " 0.226109   0.65118146 0.16768946 0.47221422 0.5180832  0.30214816\n",
      " 0.6636692  0.1834926  0.68534136 0.26515138 0.59434664 0.36775905\n",
      " 0.46614036 0.10229299 0.33874863 0.6024096  0.12471247 0.6717578\n",
      " 0.19317959 0.6931442  0.15731192 0.6709626  0.13108285 0.61022997\n",
      " 0.3383534  0.53774875 0.40016815 0.47059095 0.4517706  0.4155956\n",
      " 0.49665105 0.37347734 0.5311829  0.08144373 0.5413318  0.34616223\n",
      " 0.5393255  0.352151   0.5294241  0.36616445 0.51248753 0.38844156\n",
      " 0.4883544  0.4202931  0.4569953  0.46182185 0.41744733 0.51315093\n",
      " 0.37151256 0.5713198  0.09970798 0.6191206  0.10913298 0.6526758\n",
      " 0.24762505 0.6803694  0.20685008 0.6931423  0.1730853  0.6796305\n",
      " 0.21474084 0.06124846 0.25526756 0.6067525  0.30077517 0.558288\n",
      " 0.07968814 0.49028897], shape=(200,), dtype=float32)\n",
      "hp\n",
      "<__main__.HyperParameters object at 0x7f679402ecf8>\n",
      "hyperparameters\n",
      "<__main__.HyperParameters object at 0x7f679402ecf8>\n",
      "kargs\n",
      "{}\n",
      "logits\n",
      "tf.Tensor(\n",
      "[[ 0.3365453  -0.45729557]\n",
      " [-1.1073081   1.2941074 ]\n",
      " [ 0.39411232 -0.5292669 ]\n",
      " [-1.0733767   1.2544929 ]\n",
      " [ 0.4328505  -0.5775919 ]\n",
      " [-1.0517356   1.2295997 ]\n",
      " [ 0.4543219  -0.60495186]\n",
      " [ 1.2312918  -1.5590185 ]\n",
      " [ 1.8588357  -2.3553324 ]\n",
      " [ 1.2972263  -1.638717  ]\n",
      " [ 0.62141085 -0.80870426]\n",
      " [-0.8415375   0.9723364 ]\n",
      " [ 0.71496177 -0.9278539 ]\n",
      " [-0.7447656   0.85296166]\n",
      " [ 0.7948297  -1.0306768 ]\n",
      " [-0.6487738   0.73369753]\n",
      " [-1.7730646   2.0371518 ]\n",
      " [-0.5944203   0.6649376 ]\n",
      " [ 0.886981   -1.1494505 ]\n",
      " [-0.54748845  0.6039268 ]\n",
      " [ 0.91985327 -1.1906854 ]\n",
      " [ 1.5662869  -1.9931227 ]\n",
      " [ 0.9791328  -1.2622335 ]\n",
      " [ 1.6223077  -2.0627077 ]\n",
      " [ 1.0615773  -1.3655553 ]\n",
      " [-0.23300312  0.20104021]\n",
      " [-1.5038115   1.7305534 ]\n",
      " [-0.11852445  0.05527942]\n",
      " [-1.4445026   1.6612608 ]\n",
      " [-0.04305629 -0.04176794]\n",
      " [-1.4087653   1.6189829 ]\n",
      " [-0.00466532 -0.09249462]\n",
      " [-1.3987209   1.6054317 ]\n",
      " [-2.4024215   2.7487233 ]\n",
      " [-1.4422319   1.651721  ]\n",
      " [-0.10572156  0.02458882]\n",
      " [-1.5107342   1.7277377 ]\n",
      " [-0.22713897  0.17192118]\n",
      " [ 1.0563881  -1.3756661 ]\n",
      " [ 1.6411486  -2.1072798 ]\n",
      " [ 1.0244193  -1.3313808 ]\n",
      " [-0.3881394   0.37844953]\n",
      " [ 0.99228686 -1.2912184 ]\n",
      " [-0.4435617   0.447565  ]\n",
      " [ 0.96201885 -1.2532426 ]\n",
      " [-0.4953013   0.5119515 ]\n",
      " [ 0.9323957  -1.2154677 ]\n",
      " [-0.54442084  0.57291776]\n",
      " [ 0.90288854 -1.1774368 ]\n",
      " [-0.5917535   0.6324941 ]\n",
      " [ 0.8721172  -1.1375645 ]\n",
      " [-0.63734007  0.6907661 ]\n",
      " [ 0.8399751  -1.0960324 ]\n",
      " [-0.684248    0.75107443]\n",
      " [-1.8448466   2.122395  ]\n",
      " [-0.768492    0.85598433]\n",
      " [ 0.71258295 -0.93494725]\n",
      " [-0.86244357  0.97885484]\n",
      " [ 0.627254   -0.8278989 ]\n",
      " [-0.9605236   1.1039565 ]\n",
      " [ 0.5309855  -0.70541453]\n",
      " [-1.0641105   1.2301853 ]\n",
      " [-2.0668402   2.3927534 ]\n",
      " [-1.1971354   1.385813  ]\n",
      " [ 0.21210606 -0.3151985 ]\n",
      " [-1.3185688   1.5311446 ]\n",
      " [-0.00321064 -0.0509999 ]\n",
      " [ 0.8594668  -1.0850732 ]\n",
      " [ 1.4478309  -1.8310058 ]\n",
      " [ 0.773909   -0.97300196]\n",
      " [-0.3459121   0.37923422]\n",
      " [-1.5645149   1.8304467 ]\n",
      " [-0.5082605   0.57973444]\n",
      " [ 0.5802783  -0.72869456]\n",
      " [-0.6662586   0.77919877]\n",
      " [ 0.48306352 -0.605097  ]\n",
      " [ 1.1291571  -1.4108601 ]\n",
      " [ 0.4162601  -0.51807845]\n",
      " [-0.878387    1.0356334 ]\n",
      " [ 0.34779957 -0.4327475 ]\n",
      " [-0.9500054   1.1224359 ]\n",
      " [ 0.27673557 -0.34479547]\n",
      " [-1.0097021   1.1935657 ]\n",
      " [ 0.20307465 -0.2537818 ]\n",
      " [ 0.89666975 -1.1079414 ]\n",
      " [ 0.15725383 -0.19525032]\n",
      " [-1.0869434   1.2871795 ]\n",
      " [-1.9268248   2.2643466 ]\n",
      " [-1.1422149   1.3515615 ]\n",
      " [-0.01369728  0.0109489 ]\n",
      " [ 0.70006424 -0.85867965]\n",
      " [-0.09438368  0.11179748]\n",
      " [-1.2335525   1.463171  ]\n",
      " [-0.18637608  0.22540337]\n",
      " [ 0.56800926 -0.6901083 ]\n",
      " [-0.26179472  0.31924933]\n",
      " [ 0.5205897  -0.6288302 ]\n",
      " [-0.31742176  0.3890357 ]\n",
      " [ 0.48732838 -0.586081  ]\n",
      " [-0.35547957  0.4374233 ]\n",
      " [ 0.4677967  -0.56078064]\n",
      " [-0.37528172  0.46174362]\n",
      " [ 0.46108326 -0.5518583 ]\n",
      " [-0.37802157  0.46424899]\n",
      " [ 0.46739674 -0.5595846 ]\n",
      " [-0.36417744  0.44596115]\n",
      " [-1.3397658   1.5932903 ]\n",
      " [-0.36644015  0.44849226]\n",
      " [ 0.47315237 -0.568223  ]\n",
      " [ 1.1689656  -1.4371958 ]\n",
      " [ 0.52054465 -0.6261785 ]\n",
      " [-0.2778388   0.33540556]\n",
      " [ 0.5810438  -0.70272815]\n",
      " [-0.19397646  0.2293817 ]\n",
      " [ 0.6563413  -0.7981717 ]\n",
      " [-0.08975261  0.09816326]\n",
      " [ 0.7471887  -0.91412544]\n",
      " [ 0.03166072 -0.05518251]\n",
      " [ 0.85590005 -1.0529411 ]\n",
      " [ 1.5732962  -1.9585059 ]\n",
      " [ 2.2710822  -2.8368149 ]\n",
      " [ 1.771536   -2.205345  ]\n",
      " [ 1.2674863  -1.5671293 ]\n",
      " [ 0.706582   -0.8875783 ]\n",
      " [-0.21016121  0.21358769]\n",
      " [ 0.9682342  -1.20794   ]\n",
      " [ 0.19995219 -0.2967043 ]\n",
      " [ 1.2241929  -1.530714  ]\n",
      " [ 0.5804269  -0.7770142 ]\n",
      " [ 1.4598771  -1.8391254 ]\n",
      " [ 0.92591625 -1.1971211 ]\n",
      " [-0.18734495  0.14312544]\n",
      " [-1.2840846   1.472991  ]\n",
      " [ 0.22515102 -0.36688447]\n",
      " [ 1.3950553  -1.7850866 ]\n",
      " [ 0.6328552  -0.8798251 ]\n",
      " [-0.6339891   0.6721307 ]\n",
      " [ 0.99518013 -1.320512  ]\n",
      " [-0.2780799   0.2148818 ]\n",
      " [-1.4388163   1.61645   ]\n",
      " [ 0.05036151 -0.20051394]\n",
      " [-1.200026    1.319366  ]\n",
      " [ 0.3551994  -0.5819274 ]\n",
      " [-0.96388745  1.0245807 ]\n",
      " [ 0.62557054 -0.9142441 ]\n",
      " [ 1.6568956  -2.1802201 ]\n",
      " [ 0.88989776 -1.239011  ]\n",
      " [-0.49065638  0.40332767]\n",
      " [-1.7018894   1.8767381 ]\n",
      " [-0.28306624  0.13510169]\n",
      " [ 1.2773879  -1.7056165 ]\n",
      " [-0.09494315 -0.09981561]\n",
      " [ 1.4029987  -1.8645809 ]\n",
      " [ 0.0922881  -0.33375582]\n",
      " [ 1.5060272  -2.006682  ]\n",
      " [ 0.28284657 -0.56801116]\n",
      " [-1.0719417   1.0589216 ]\n",
      " [ 0.4456468  -0.76979584]\n",
      " [-0.9488593   0.888413  ]\n",
      " [ 0.58104527 -0.9388879 ]\n",
      " [-0.8496152   0.7544128 ]\n",
      " [ 0.6904865  -1.076346  ]\n",
      " [-0.76221895  0.6409712 ]\n",
      " [ 0.7760079  -1.1854024 ]\n",
      " [-0.6940886   0.55184907]\n",
      " [-1.9913832   2.1367855 ]\n",
      " [-0.67582214  0.5228701 ]\n",
      " [ 0.82950103 -1.2629659 ]\n",
      " [-0.68226105  0.52582073]\n",
      " [ 0.81426597 -1.249054  ]\n",
      " [-0.7050195   0.5490461 ]\n",
      " [ 0.7819332  -1.2141132 ]\n",
      " [-0.7420545   0.589551  ]\n",
      " [ 0.73272145 -1.1586895 ]\n",
      " [-0.7930689   0.64738667]\n",
      " [ 0.66502404 -1.0805086 ]\n",
      " [-0.857856    0.7228144 ]\n",
      " [ 0.57897234 -0.98013306]\n",
      " [-0.93941784  0.819011  ]\n",
      " [ 0.47315016 -0.8554398 ]\n",
      " [-1.0366634   0.93402284]\n",
      " [ 0.3474242  -0.70715857]\n",
      " [ 1.6290672  -2.2410417 ]\n",
      " [ 0.23179676 -0.568206  ]\n",
      " [ 1.5783571  -2.1749444 ]\n",
      " [ 0.13292928 -0.44801268]\n",
      " [-1.3305247   1.2921855 ]\n",
      " [ 0.01472531 -0.30706242]\n",
      " [-1.448719    1.4370928 ]\n",
      " [-0.13464402 -0.12837459]\n",
      " [ 1.3025014  -1.8339509 ]\n",
      " [-0.28211322  0.04897252]\n",
      " [ 1.1672101  -1.6647815 ]\n",
      " [ 1.9041421  -2.5804157 ]\n",
      " [ 1.0535815  -1.5234585 ]\n",
      " [-0.52602184  0.34418258]\n",
      " [ 0.9380048  -1.3849494 ]\n",
      " [-0.63868773  0.47949448]\n",
      " [-2.0037682   2.1519268 ]\n",
      " [-0.781077    0.6507    ]], shape=(200, 2), dtype=float32)\n",
      "observations\n",
      "[array([ 0.01713991,  0.0188456 , -0.01783879, -0.02126413]), array([ 0.01751682, -0.17601604, -0.01826408,  0.2657375 ]), array([ 0.0139965 ,  0.01936176, -0.01294933, -0.03264966]), array([ 0.01438374, -0.17557212, -0.01360232,  0.25591965]), array([ 0.0108723 ,  0.01974137, -0.00848393, -0.04102244]), array([ 0.01126712, -0.1752579 , -0.00930437,  0.2489717 ]), array([ 0.00776196,  0.01999568, -0.00432494, -0.04663144]), array([ 0.00816188,  0.21517938, -0.00525757, -0.34067578]), array([ 0.01246547,  0.41037574, -0.01207109, -0.635012  ]), array([ 0.02067298,  0.21542422, -0.02477133, -0.34615483]), array([ 0.02498146,  0.02066323, -0.03169442, -0.061385  ]), array([ 0.02539473, -0.1739903 , -0.03292212,  0.22113205]), array([ 0.02191492,  0.02158639, -0.02849948, -0.08175136]), array([ 0.02234665, -0.17311568, -0.03013451,  0.20180542]), array([ 0.01888434,  0.022424  , -0.0260984 , -0.10022913]), array([ 0.01933282, -0.17231439, -0.02810298,  0.18410691]), array([ 0.01588653, -0.36702319, -0.02442084,  0.46779361]), array([ 0.00854607, -0.17156489, -0.01506497,  0.16751456]), array([ 0.00511477,  0.02376943, -0.01171468, -0.1298826 ]), array([ 0.00559016, -0.17118277, -0.01431233,  0.15908159]), array([ 0.0021665 ,  0.02414113, -0.0111307 , -0.13808194]), array([ 0.00264932,  0.21942072, -0.01389234, -0.43425554]), array([ 0.00703774,  0.02449818, -0.02257745, -0.14598415]), array([ 0.0075277 ,  0.21993606, -0.02549713, -0.44570346]), array([ 0.01192642,  0.02518394, -0.0344112 , -0.16116557]), array([ 0.0124301 , -0.16942891, -0.03763451,  0.12046599]), array([ 0.00904152, -0.36399202, -0.03522519,  0.40104206]), array([ 0.00176168, -0.16838858, -0.02720435,  0.09746485]), array([-0.00160609, -0.36311029, -0.02525506,  0.38144223]), array([-0.00886829, -0.167639  , -0.01762621,  0.08090461]), array([-0.01222107, -0.3625039 , -0.01600812,  0.36797472]), array([-0.01947115, -0.16715819, -0.00864863,  0.0702875 ]), array([-0.02281432, -0.36215508, -0.00724288,  0.36022925]), array([-3.00574175e-02, -5.57173334e-01, -3.82901606e-05,  6.50619561e-01]), array([-0.04120088, -0.36205085,  0.0129741 ,  0.35792458]), array([-0.0484419 , -0.16711572,  0.02013259,  0.06936078]), array([-0.05178422, -0.36252044,  0.02151981,  0.36832703]), array([-0.05903462, -0.16771077,  0.02888635,  0.08250653]), array([-0.06238884,  0.02698545,  0.03053648, -0.20092456]), array([-0.06184913,  0.22165766,  0.02651799, -0.48382041]), array([-0.05741598,  0.02617169,  0.01684158, -0.18289918]), array([-0.05689254, -0.16918715,  0.0131836 ,  0.11504871]), array([-0.06027629,  0.02574345,  0.01548457, -0.1734459 ]), array([-0.05976142, -0.16959666,  0.01201565,  0.12408141]), array([-0.06315335,  0.02535111,  0.01449728, -0.16478662]), array([-0.06264633, -0.16997534,  0.01120155,  0.13243432]), array([-0.06604584,  0.02498438,  0.01385023, -0.15669373]), array([-0.06554615, -0.17033311,  0.01071636,  0.14032624]), array([-0.06895281,  0.02463374,  0.01352288, -0.14895668]), array([-0.06846014, -0.17067922,  0.01054375,  0.14796158]), array([-0.07187372,  0.02429017,  0.01350298, -0.14137645]), array([-0.07138792, -0.17102255,  0.01067545,  0.15553567]), array([-0.07480837,  0.02394494,  0.01378617, -0.13376037]), array([-0.07432947, -0.17137174,  0.01111096,  0.16323981]), array([-0.0777569 , -0.36665097,  0.01437576,  0.45940714]), array([-0.08508992, -0.17173515,  0.0235639 ,  0.17128994]), array([-0.08852463,  0.02304175,  0.0269897 , -0.11386715]), array([-0.08806379, -0.17245633,  0.02471235,  0.18720717]), array([-0.09151292,  0.0223035 ,  0.0284565 , -0.09757868]), array([-0.09106685, -0.17321449,  0.02650492,  0.20394466]), array([-0.09453114,  0.02151858,  0.03058382, -0.08026083]), array([-0.09410077, -0.17402814,  0.0289786 ,  0.22191233]), array([-0.09758133, -0.36955205,  0.03341685,  0.52359357]), array([-0.10497237, -0.17491595,  0.04388872,  0.24162514]), array([-0.10847069,  0.01955249,  0.04872122, -0.03689748]), array([-0.10807964, -0.17623305,  0.04798327,  0.27075071]), array([-0.1116043 ,  0.01817251,  0.05339829, -0.00642033]), array([-0.11124085,  0.21248961,  0.05326988, -0.28178888]), array([-0.10699106,  0.40681285,  0.0476341 , -0.55720633]), array([-0.0988548 ,  0.21105569,  0.03648998, -0.24990453]), array([-0.09463369,  0.01543216,  0.03149189,  0.05406111]), array([-0.09432504, -0.18012686,  0.03257311,  0.35651127]), array([-0.09792758,  0.01451721,  0.03970333,  0.07427484]), array([-0.09763724,  0.20904814,  0.04118883, -0.20562188]), array([-0.09345627,  0.01336213,  0.03707639,  0.09976428]), array([-0.09318903,  0.20793363,  0.03907168, -0.18099444]), array([-0.08903036,  0.40247534,  0.03545179, -0.46110014]), array([-0.08098085,  0.20687071,  0.02622979, -0.15745692]), array([-0.07684344,  0.01138324,  0.02308065,  0.1433841 ]), array([-0.07661577,  0.20616717,  0.02594833, -0.14192886]), array([-0.07249243,  0.01068338,  0.02310975,  0.15882605]), array([-0.07227876,  0.20546698,  0.02628627, -0.12647767]), array([-0.06816942,  0.00997851,  0.02375672,  0.17438101]), array([-0.06796985,  0.20475255,  0.02724434, -0.11071379]), array([-0.0638748 ,  0.39947372,  0.02503006, -0.39467831]), array([-0.05588533,  0.20400572,  0.0171365 , -0.09421007]), array([-0.05180521,  0.0086424 ,  0.0152523 ,  0.20382977]), array([-0.05163236, -0.18669432,  0.01932889,  0.50128476]), array([-0.05536625,  0.00814991,  0.02935459,  0.21475535]), array([-0.05520325,  0.20284016,  0.03364969, -0.06852521]), array([-0.05114645,  0.39746393,  0.03227919, -0.35040445]), array([-0.04319717,  0.20189814,  0.0252711 , -0.04772014]), array([-0.03915921,  0.00642311,  0.0243167 ,  0.2528277 ]), array([-0.03903075,  0.20118955,  0.02937325, -0.03208719]), array([-0.03500696,  0.39587823,  0.02873151, -0.31535974]), array([-0.02708939,  0.20035905,  0.02242431, -0.01375611]), array([-0.02308221,  0.39515235,  0.02214919, -0.2992804 ]), array([-0.01517916,  0.1997218 ,  0.01616358,  0.00030485]), array([-0.01118473,  0.39460825,  0.01616968, -0.28723477]), array([-0.00329256,  0.19925948,  0.01042498,  0.01050376]), array([ 0.00069263,  0.39423039,  0.01063506, -0.27887181]), array([0.00857724, 0.19895835, 0.00505762, 0.01714633]), array([ 0.0125564 ,  0.3940074 ,  0.00540055, -0.27393657]), array([ 2.04365506e-02,  1.98808814e-01, -7.81809182e-05,  2.04447941e-02]), array([ 2.44127269e-02,  3.93931886e-01,  3.30714963e-04, -2.72262799e-01]), array([ 0.03229136,  0.19880522, -0.00511454,  0.02052442]), array([ 0.03626747,  0.00375699, -0.00470405,  0.31158927]), array([0.03634261, 0.19894564, 0.00152773, 0.01742655]), array([ 0.04032152,  0.39404565,  0.00187626, -0.27477397]), array([ 0.04820243,  0.58914078, -0.00361922, -0.56686453]), array([ 0.05998525,  0.39406978, -0.01495651, -0.275324  ]), array([ 0.06786665,  0.19916438, -0.02046299,  0.01260435]), array([ 0.07184993,  0.39457373, -0.0202109 , -0.28646401]), array([ 0.07974141,  0.19974576, -0.02594018, -0.00022333]), array([ 0.08373632,  0.39522994, -0.02594465, -0.30097651]), array([ 0.09164092,  0.2004872 , -0.03196418, -0.01658759]), array([ 0.09565067,  0.39605263, -0.03229593, -0.31918175]), array([ 0.10357172,  0.20140517, -0.03867956, -0.03685617]), array([ 0.10759982,  0.39705983, -0.03941669, -0.3414876 ]), array([ 0.11554102,  0.59271977, -0.04624644, -0.64633506]), array([ 0.12739541,  0.78845457, -0.05917314, -0.95321495]), array([ 0.14316451,  0.59417656, -0.07823744, -0.67969473]), array([ 0.15504804,  0.40022354, -0.09183133, -0.4126335 ]), array([ 0.16305251,  0.20651515, -0.100084  , -0.15025569]), array([ 0.16718281,  0.01295818, -0.10308912,  0.10925127]), array([ 0.16744197,  0.20939472, -0.10090409, -0.21409377]), array([ 0.17162987,  0.01584927, -0.10518597,  0.04513221]), array([ 0.17194685,  0.21230997, -0.10428332, -0.27879778]), array([ 0.17619305,  0.01881829, -0.10985928, -0.02074076]), array([ 0.17656942,  0.21533025, -0.11027409, -0.3459654 ]), array([ 0.18087602,  0.02193554, -0.1171934 , -0.08999026]), array([ 0.18131474, -0.17132863, -0.11899321,  0.16354145]), array([ 0.17788816, -0.36456395, -0.11572238,  0.41644328]), array([ 0.17059688, -0.16800842, -0.10739351,  0.08963545]), array([ 0.16723672,  0.02847588, -0.1056008 , -0.23490607]), array([ 0.16780623, -0.16499124, -0.11029893,  0.02268904]), array([ 0.16450641, -0.35837274, -0.10984514,  0.27863643]), array([ 0.15733895, -0.16186919, -0.10427242, -0.046572  ]), array([ 0.15410157, -0.35535339, -0.10520386,  0.21147738]), array([ 0.1469945 , -0.54882614, -0.10097431,  0.46920909]), array([ 0.13601798, -0.35243357, -0.09159013,  0.14648471]), array([ 0.12896931, -0.54613267, -0.08866043,  0.40892567]), array([ 0.11804665, -0.34987288, -0.08048192,  0.08966026]), array([ 0.1110492 , -0.54375452, -0.07868871,  0.3559052 ]), array([ 0.10017411, -0.34760711, -0.07157061,  0.03948389]), array([ 0.09322196, -0.1515357 , -0.07078093, -0.27489408]), array([ 0.09019125, -0.34558014, -0.07627881, -0.00534845]), array([ 0.08327965, -0.53952997, -0.07638578,  0.2623261 ]), array([ 0.07248905, -0.73348317, -0.07113926,  0.52997198]), array([ 0.05781938, -0.53743637, -0.06053982,  0.21574827]), array([ 0.04707066, -0.34150354, -0.05622486, -0.0954004 ]), array([ 0.04024059, -0.53577645, -0.05813286,  0.17902708]), array([ 0.02952506, -0.33987287, -0.05455232, -0.13141333]), array([ 0.0227276 , -0.53417266, -0.05718059,  0.14357236]), array([ 0.01204415, -0.33828041, -0.05430914, -0.16658771]), array([ 0.00527854, -0.53258459, -0.0576409 ,  0.10847981]), array([-0.00537315, -0.72683521, -0.0554713 ,  0.38243478]), array([-0.01990986, -0.53097131, -0.0478226 ,  0.07279064]), array([-0.03052928, -0.7253762 , -0.04636679,  0.3500101 ]), array([-0.04503681, -0.52962655, -0.03936659,  0.04307423]), array([-0.05562934, -0.72416253, -0.0385051 ,  0.32308134]), array([-0.07011259, -0.52851404, -0.03204348,  0.01850843]), array([-0.08068287, -0.72316215, -0.03167331,  0.30091154]), array([-0.09514611, -0.52760341, -0.02565508, -0.00158984]), array([-0.10569818, -0.72234821, -0.02568687,  0.28288947]), array([-0.12014515, -0.91709454, -0.02002908,  0.56736149]), array([-0.13848704, -0.72169745, -0.00868186,  0.26843648]), array([-0.15292099, -0.52645268, -0.00331313, -0.02697207]), array([-0.16345004, -0.72152696, -0.00385257,  0.26466369]), array([-0.17788058, -0.52635023,  0.00144071, -0.02923188]), array([-0.18840758, -0.72149282,  0.00085607,  0.26390526]), array([-0.20283744, -0.52638309,  0.00613417, -0.02850753]), array([-0.2133651 , -0.72159247,  0.00556402,  0.26610446]), array([-0.22779695, -0.52655037,  0.01088611, -0.02481834]), array([-0.23832796, -0.72182674,  0.01038975,  0.2712793 ]), array([-0.25276449, -0.52685457,  0.01581533, -0.01810863]), array([-0.26330158, -0.72219972,  0.01545316,  0.27952196]), array([-0.27774558, -0.52730158,  0.0210436 , -0.0082473 ]), array([-0.28829161, -0.72271891,  0.02087865,  0.29100015]), array([-0.30274599, -0.52790079,  0.02669866,  0.00497454]), array([-0.313304  , -0.72339526,  0.02679815,  0.30596022]), array([-0.32777191, -0.52866523,  0.03291735,  0.02184776]), array([-0.33834521, -0.33403044,  0.03335431, -0.26027032]), array([-0.34502582, -0.52961226,  0.0281489 ,  0.04274359]), array([-0.35561807, -0.33490503,  0.02900377, -0.24092687]), array([-0.36231617, -0.53042903,  0.02418523,  0.06076169]), array([-0.37292475, -0.72588925,  0.02540047,  0.36097604]), array([-0.38744253, -0.53113738,  0.03261999,  0.07640941]), array([-0.39806528, -0.72671141,  0.03414818,  0.37920297]), array([-0.41259951, -0.53209063,  0.04173224,  0.09747959]), array([-0.42324132, -0.33759087,  0.04368183, -0.18175032]), array([-0.42999314, -0.53330977,  0.04004682,  0.12438636]), array([-0.44065934, -0.33878374,  0.04253455, -0.15539811]), array([-0.44743501, -0.14429579,  0.03942659, -0.43436479]), array([-0.45032093, -0.33995309,  0.03073929, -0.12951849]), array([-0.45711999, -0.53550159,  0.02814892,  0.17270162]), array([-0.46783002, -0.34079359,  0.03160295, -0.11096999]), array([-0.47464589, -0.53635381,  0.02938355,  0.19151358]), array([-0.48537297, -0.73188352,  0.03321383,  0.49331906]), array([-0.50001064, -0.53724538,  0.04308021,  0.21128593])]\n",
      "policy\n",
      "tf.Tensor(\n",
      "[[0.68865544 0.31134453]\n",
      " [0.08306481 0.91693515]\n",
      " [0.7157302  0.28426987]\n",
      " [0.08884097 0.911159  ]\n",
      " [0.73310673 0.2668933 ]\n",
      " [0.0926806  0.9073194 ]\n",
      " [0.7425517  0.25744826]\n",
      " [0.94214994 0.05785003]\n",
      " [0.98543084 0.01456922]\n",
      " [0.949595   0.05040509]\n",
      " [0.8069192  0.19308074]\n",
      " [0.14017059 0.8598295 ]\n",
      " [0.83791775 0.1620823 ]\n",
      " [0.1682995  0.8317005 ]\n",
      " [0.86122555 0.13877444]\n",
      " [0.2006124  0.7993876 ]\n",
      " [0.02166368 0.97833633]\n",
      " [0.22108445 0.7789155 ]\n",
      " [0.8845694  0.11543059]\n",
      " [0.24023068 0.7597693 ]\n",
      " [0.89192325 0.10807672]\n",
      " [0.9723317  0.0276683 ]\n",
      " [0.90390325 0.09609679]\n",
      " [0.97551763 0.02448237]\n",
      " [0.9188731  0.08112696]\n",
      " [0.39316127 0.60683876]\n",
      " [0.03789279 0.96210724]\n",
      " [0.4566581  0.54334193]\n",
      " [0.04287015 0.9571299 ]\n",
      " [0.4996779  0.50032204]\n",
      " [0.04618793 0.953812  ]\n",
      " [0.5219432  0.47805676]\n",
      " [0.04723862 0.9527613 ]\n",
      " [0.00575941 0.99424064]\n",
      " [0.04335738 0.9566426 ]\n",
      " [0.46746844 0.53253156]\n",
      " [0.03774335 0.96225667]\n",
      " [0.40153816 0.5984618 ]\n",
      " [0.91923916 0.08076083]\n",
      " [0.97698736 0.02301268]\n",
      " [0.91339415 0.08660584]\n",
      " [0.31721747 0.6827826 ]\n",
      " [0.9075017  0.0924983 ]\n",
      " [0.29087737 0.70912266]\n",
      " [0.9016116  0.09838834]\n",
      " [0.2675178  0.7324822 ]\n",
      " [0.89546895 0.10453104]\n",
      " [0.24650528 0.75349474]\n",
      " [0.8889761  0.11102384]\n",
      " [0.2271898  0.77281016]\n",
      " [0.8818099  0.11819015]\n",
      " [0.2094728  0.79052716]\n",
      " [0.87391293 0.12608713]\n",
      " [0.19227076 0.8077293 ]\n",
      " [0.01857404 0.981426  ]\n",
      " [0.16458847 0.83541155]\n",
      " [0.838557   0.16144302]\n",
      " [0.13689782 0.86310214]\n",
      " [0.81079024 0.18920977]\n",
      " [0.11259741 0.8874026 ]\n",
      " [0.77493674 0.22506322]\n",
      " [0.09159648 0.9084035 ]\n",
      " [0.01143479 0.98856515]\n",
      " [0.07024392 0.9297561 ]\n",
      " [0.6288542  0.37114576]\n",
      " [0.05469614 0.9453039 ]\n",
      " [0.51194507 0.48805496]\n",
      " [0.87485003 0.12514994]\n",
      " [0.96369565 0.03630439]\n",
      " [0.8515628  0.14843725]\n",
      " [0.32626075 0.67373925]\n",
      " [0.0324533  0.96754676]\n",
      " [0.25199604 0.74800396]\n",
      " [0.7873412  0.21265876]\n",
      " [0.19070168 0.80929834]\n",
      " [0.7480352  0.25196484]\n",
      " [0.92689997 0.07310001]\n",
      " [0.71795464 0.28204533]\n",
      " [0.12852985 0.87147015]\n",
      " [0.68579805 0.31420198]\n",
      " [0.11180437 0.88819563]\n",
      " [0.65056664 0.3494333 ]\n",
      " [0.09945742 0.90054256]\n",
      " [0.6122682  0.38773185]\n",
      " [0.88128036 0.11871965]\n",
      " [0.58722466 0.4127753 ]\n",
      " [0.08516736 0.9148326 ]\n",
      " [0.01490309 0.985097  ]\n",
      " [0.07629564 0.9237043 ]\n",
      " [0.49383873 0.5061612 ]\n",
      " [0.826173   0.17382695]\n",
      " [0.44863653 0.55136347]\n",
      " [0.06316698 0.936833  ]\n",
      " [0.3984855  0.6015145 ]\n",
      " [0.7787019  0.2212981 ]\n",
      " [0.35869238 0.64130765]\n",
      " [0.75940496 0.24059506]\n",
      " [0.33038208 0.66961795]\n",
      " [0.7452448  0.25475526]\n",
      " [0.31154573 0.68845433]\n",
      " [0.73664    0.26336002]\n",
      " [0.30216166 0.69783837]\n",
      " [0.73359543 0.26640454]\n",
      " [0.3010568  0.6989432 ]\n",
      " [0.7363303  0.26366976]\n",
      " [0.30786097 0.692139  ]\n",
      " [0.05054346 0.9494565 ]\n",
      " [0.30684042 0.6931596 ]\n",
      " [0.7391153  0.26088467]\n",
      " [0.93125707 0.06874294]\n",
      " [0.75891185 0.2410881 ]\n",
      " [0.3513195  0.6486805 ]\n",
      " [0.7830912  0.21690881]\n",
      " [0.39571345 0.60428655]\n",
      " [0.810692   0.18930797]\n",
      " [0.4531588  0.54684126]\n",
      " [0.8404143  0.15958565]\n",
      " [0.52169716 0.4783028 ]\n",
      " [0.8708889  0.1291111 ]\n",
      " [0.9715792  0.02842078]\n",
      " [0.99398756 0.00601242]\n",
      " [0.9816009  0.01839914]\n",
      " [0.94451797 0.05548202]\n",
      " [0.8312006  0.16879937]\n",
      " [0.39562002 0.60438   ]\n",
      " [0.89808947 0.10191055]\n",
      " [0.6216733  0.3783267 ]\n",
      " [0.94018984 0.05981012]\n",
      " [0.7953435  0.20465653]\n",
      " [0.96439457 0.03560542]\n",
      " [0.8931222  0.10687779]\n",
      " [0.41812617 0.5818738 ]\n",
      " [0.05968828 0.9403117 ]\n",
      " [0.643832   0.35616797]\n",
      " [0.96008015 0.03991989]\n",
      " [0.81945807 0.1805419 ]\n",
      " [0.21313687 0.78686315]\n",
      " [0.9101683  0.08983164]\n",
      " [0.37919614 0.6208039 ]\n",
      " [0.04499065 0.95500934]\n",
      " [0.56239194 0.43760803]\n",
      " [0.07450985 0.9254901 ]\n",
      " [0.7185189  0.28148106]\n",
      " [0.12041903 0.879581  ]\n",
      " [0.8234378  0.17656222]\n",
      " [0.9788992  0.02110084]\n",
      " [0.89368135 0.10631862]\n",
      " [0.29028833 0.7097117 ]\n",
      " [0.02715595 0.9728441 ]\n",
      " [0.39695522 0.6030448 ]\n",
      " [0.9518004  0.04819961]\n",
      " [0.50121814 0.4987819 ]\n",
      " [0.96329963 0.0367003 ]\n",
      " [0.6049286  0.3950714 ]\n",
      " [0.9710472  0.02895277]\n",
      " [0.7007471  0.29925293]\n",
      " [0.10613307 0.89386696]\n",
      " [0.77126056 0.22873947]\n",
      " [0.13737422 0.8626258 ]\n",
      " [0.8205286  0.17947136]\n",
      " [0.1674194  0.8325806 ]\n",
      " [0.8540633  0.14593667]\n",
      " [0.19731037 0.8026897 ]\n",
      " [0.8766855  0.12331451]\n",
      " [0.22340417 0.77659583]\n",
      " [0.01585687 0.98414314]\n",
      " [0.23170793 0.76829207]\n",
      " [0.8901688  0.10983116]\n",
      " [0.23004065 0.7699594 ]\n",
      " [0.8872866  0.11271338]\n",
      " [0.22199717 0.77800286]\n",
      " [0.88038135 0.11961864]\n",
      " [0.20889392 0.7911061 ]\n",
      " [0.86891633 0.13108368]\n",
      " [0.19147481 0.8085252 ]\n",
      " [0.85138845 0.14861156]\n",
      " [0.17070058 0.82929945]\n",
      " [0.8262249  0.17377505]\n",
      " [0.14698723 0.8530128 ]\n",
      " [0.7906073  0.20939271]\n",
      " [0.1223152  0.87768483]\n",
      " [0.741654   0.25834605]\n",
      " [0.97957    0.02043001]\n",
      " [0.6899751  0.31002495]\n",
      " [0.9770966  0.02290337]\n",
      " [0.6412841  0.3587159 ]\n",
      " [0.06769104 0.9323089 ]\n",
      " [0.57975984 0.4202401 ]\n",
      " [0.05285941 0.9471406 ]\n",
      " [0.49843267 0.50156736]\n",
      " [0.9583716  0.04162843]\n",
      " [0.41797647 0.5820235 ]\n",
      " [0.9443803  0.05561969]\n",
      " [0.98884404 0.01115601]\n",
      " [0.9293692  0.07063078]\n",
      " [0.29521176 0.7047882 ]\n",
      " [0.91076034 0.08923966]\n",
      " [0.2463486  0.7536514 ]\n",
      " [0.01543298 0.984567  ]\n",
      " [0.19282195 0.8071781 ]], shape=(200, 2), dtype=float32)\n",
      "total_loss\n",
      "tf.Tensor(0.15252142, shape=(), dtype=float32)\n",
      "values\n",
      "tf.Tensor(\n",
      "[ 0.77698344  0.67532676  0.7654024   0.66782004  0.75378746  0.65858394\n",
      "  0.74341875  0.5444172   0.3548389   0.5528648   0.74770886  0.71507\n",
      "  0.72091156  0.7062318   0.6948365   0.69524115  0.52312356  0.6606356\n",
      "  0.6421443   0.6517782   0.62631017  0.4247996   0.621508    0.41315103\n",
      "  0.6007129   0.666778    0.52474815  0.6315873   0.48976818  0.59944016\n",
      "  0.45677462  0.5705353   0.42470828  0.2411581   0.36241293  0.49127916\n",
      "  0.3280397   0.462918    0.43088016  0.29445145  0.46612838  0.49443102\n",
      "  0.4748997   0.4895536   0.48192346  0.48297247  0.48808283  0.47528622\n",
      "  0.49375784  0.46707723  0.49882278  0.45866898  0.50300455  0.44984943\n",
      "  0.26812077  0.4022182   0.4829391   0.389302    0.48364952  0.37407032\n",
      "  0.48028028  0.35725468  0.16587454  0.2933832   0.43247694  0.2594475\n",
      "  0.4133039   0.37231874  0.26025555  0.41559845  0.4700152   0.26570436\n",
      "  0.42943487  0.41876975  0.42578632  0.43065357  0.33773595  0.46458268\n",
      "  0.44168088  0.4656408   0.42849532  0.46437836  0.41071764  0.4610828\n",
      "  0.37098834  0.47785553  0.412234    0.18912175  0.35670495  0.4399318\n",
      "  0.36338666  0.45225713  0.33513805  0.43889713  0.35820523  0.44316778\n",
      "  0.35733795  0.44745356  0.35672975  0.45032847  0.35675162  0.4573295\n",
      "  0.35795227  0.4674981   0.36035597  0.4776104   0.3916608   0.47404766\n",
      "  0.36021835  0.19346575  0.3703083   0.5123798   0.37947428  0.5318973\n",
      "  0.3868889   0.55035204  0.39213684  0.5669274   0.3919331   0.18934448\n",
      " -0.0149206   0.17824373  0.3623822   0.5670591   0.73238426  0.5472862\n",
      "  0.72085357  0.49337676  0.68649644  0.42969832  0.62488574  0.7552418\n",
      "  0.72290033  0.71681005  0.48951027  0.6530716   0.6656945   0.5727426\n",
      "  0.6065422   0.5308744   0.5336394   0.47379562  0.4624577   0.41276708\n",
      "  0.39083424  0.20031036  0.33135727  0.31036723  0.2203604   0.2332072\n",
      "  0.16813636  0.18103218  0.09953234  0.13054377  0.03115823  0.07778865\n",
      "  0.02209346  0.01038714 -0.03534239 -0.0499472  -0.08941454 -0.10392497\n",
      " -0.14162904 -0.15391451 -0.19319507 -0.3104294  -0.26145545 -0.2615076\n",
      " -0.30633172 -0.30234835 -0.3530273  -0.34010488 -0.40178046 -0.37992215\n",
      " -0.4523522  -0.4229812  -0.50480974 -0.4700525  -0.5559554  -0.51699185\n",
      " -0.6077698  -0.56328213 -0.53074616 -0.58953965 -0.5474436  -0.6176949\n",
      " -0.7327879  -0.67421997 -0.79606336 -0.7323538  -0.66722405 -0.7715096\n",
      " -0.70199513 -0.6971349  -0.71606857 -0.8283447  -0.75290143 -0.8708723\n",
      " -1.0008478  -0.94097644], shape=(200,), dtype=float32)\n",
      "verbose\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "observations, actions, rewards = run(env, a2c, verbose=False)\n",
    "discounted_rewards = get_discounted_rewards(rewards, hp.gamma)\n",
    "learn(a2c, observations, actions, discounted_rewards, hyperparameters=hp, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "linkText": "Export to plot.ly",
        "plotlyServerURL": "https://plot.ly",
        "showLink": false
       },
       "data": [
        {
         "type": "scatter",
         "uid": "b92fc5b2-10d3-4612-b11f-3c2c82787238",
         "x": [
          0,
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99
         ],
         "y": [
          18.8,
          18.7,
          19.7,
          19,
          16.9,
          15.7,
          14.3,
          13.6,
          15.1,
          15.3,
          15.5,
          16.8,
          16.8,
          17.2,
          17,
          18.2,
          18,
          18.5,
          17.9,
          17.3,
          18.4,
          19.5,
          20.3,
          20.8,
          20.9,
          20.3,
          22.2,
          22,
          20.4,
          31.2,
          34.4,
          33.6,
          39,
          39.7,
          48.4,
          49.9,
          50.3,
          52.8,
          54.5,
          45.9,
          44.4,
          52.2,
          46.5,
          51.1,
          59,
          73.9,
          81,
          81.4,
          86.1,
          84.5,
          88.9,
          88.1,
          99.4,
          101.8,
          99.8,
          95.2,
          95.5,
          105,
          104.8,
          122.7,
          123.2,
          124.6,
          118,
          123.4,
          115.1,
          110.6,
          108.2,
          106.6,
          118.9,
          118.9,
          129.6,
          123.1,
          122.6,
          113.6,
          115.1,
          115.1,
          113.8,
          114.9,
          114.1,
          105.8,
          105.8,
          121.2,
          134,
          147.9,
          159,
          170,
          182.8,
          188.9,
          180,
          184.7,
          184.7
         ]
        }
       ],
       "layout": {
        "autosize": true,
        "title": {
         "text": "Reward Per Episode"
        },
        "xaxis": {
         "autorange": true,
         "range": [
          0,
          90
         ],
         "type": "linear"
        },
        "yaxis": {
         "autorange": true,
         "range": [
          3.8611111111111107,
          198.63888888888889
         ],
         "type": "linear"
        }
       }
      },
      "image/png": "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",
      "text/html": [
       "<div id=\"55f9bde5-bbca-4f30-a2e5-e2a5341e18cc\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"55f9bde5-bbca-4f30-a2e5-e2a5341e18cc\", [{\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [18.8, 18.7, 19.7, 19.0, 16.9, 15.7, 14.3, 13.6, 15.1, 15.3, 15.5, 16.8, 16.8, 17.2, 17.0, 18.2, 18.0, 18.5, 17.9, 17.3, 18.4, 19.5, 20.3, 20.8, 20.9, 20.3, 22.2, 22.0, 20.4, 31.2, 34.4, 33.6, 39.0, 39.7, 48.4, 49.9, 50.3, 52.8, 54.5, 45.9, 44.4, 52.2, 46.5, 51.1, 59.0, 73.9, 81.0, 81.4, 86.1, 84.5, 88.9, 88.1, 99.4, 101.8, 99.8, 95.2, 95.5, 105.0, 104.8, 122.7, 123.2, 124.6, 118.0, 123.4, 115.1, 110.6, 108.2, 106.6, 118.9, 118.9, 129.6, 123.1, 122.6, 113.6, 115.1, 115.1, 113.8, 114.9, 114.1, 105.8, 105.8, 121.2, 134.0, 147.9, 159.0, 170.0, 182.8, 188.9, 180.0, 184.7, 184.7], \"type\": \"scatter\", \"uid\": \"1c5554a3-a5de-4996-8533-5d7d29bf6b4f\"}], {\"title\": {\"text\": \"Reward Per Episode\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"55f9bde5-bbca-4f30-a2e5-e2a5341e18cc\"));});</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<div id=\"55f9bde5-bbca-4f30-a2e5-e2a5341e18cc\" style=\"height: 525px; width: 100%;\" class=\"plotly-graph-div\"></div><script type=\"text/javascript\">require([\"plotly\"], function(Plotly) { window.PLOTLYENV=window.PLOTLYENV || {};window.PLOTLYENV.BASE_URL=\"https://plot.ly\";Plotly.newPlot(\"55f9bde5-bbca-4f30-a2e5-e2a5341e18cc\", [{\"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99], \"y\": [18.8, 18.7, 19.7, 19.0, 16.9, 15.7, 14.3, 13.6, 15.1, 15.3, 15.5, 16.8, 16.8, 17.2, 17.0, 18.2, 18.0, 18.5, 17.9, 17.3, 18.4, 19.5, 20.3, 20.8, 20.9, 20.3, 22.2, 22.0, 20.4, 31.2, 34.4, 33.6, 39.0, 39.7, 48.4, 49.9, 50.3, 52.8, 54.5, 45.9, 44.4, 52.2, 46.5, 51.1, 59.0, 73.9, 81.0, 81.4, 86.1, 84.5, 88.9, 88.1, 99.4, 101.8, 99.8, 95.2, 95.5, 105.0, 104.8, 122.7, 123.2, 124.6, 118.0, 123.4, 115.1, 110.6, 108.2, 106.6, 118.9, 118.9, 129.6, 123.1, 122.6, 113.6, 115.1, 115.1, 113.8, 114.9, 114.1, 105.8, 105.8, 121.2, 134.0, 147.9, 159.0, 170.0, 182.8, 188.9, 180.0, 184.7, 184.7], \"type\": \"scatter\", \"uid\": \"1c5554a3-a5de-4996-8533-5d7d29bf6b4f\"}], {\"title\": {\"text\": \"Reward Per Episode\"}}, {\"showLink\": false, \"linkText\": \"Export to plot.ly\", \"plotlyServerURL\": \"https://plot.ly\"})});</script><script type=\"text/javascript\">window.addEventListener(\"resize\", function(){window._Plotly.Plots.resize(document.getElementById(\"55f9bde5-bbca-4f30-a2e5-e2a5341e18cc\"));});</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plotly.offline.iplot({\n",
    "    \"data\": [go.Scatter(x=np.arange(len(ep_rewards)), y=moving_average(ep_rewards, 10))],\n",
    "    \"layout\": go.Layout(title=\"Reward Per Episode\")\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
