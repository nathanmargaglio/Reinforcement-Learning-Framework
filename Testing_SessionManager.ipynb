{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "from SessionManager import SessionManager, Session, Episode, Agent\n",
    "from sqlalchemy import desc, asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/.conda/envs/tensorflow/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "sm = SessionManager()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of SessionManager failed: Traceback (most recent call last):\n",
      "  File \"/home/nathan/.conda/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 244, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/nathan/.conda/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 392, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/nathan/.conda/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 329, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/nathan/.conda/envs/tensorflow/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 277, in update_class\n",
      "    if old_obj == new_obj:\n",
      "  File \"/home/nathan/.conda/envs/tensorflow/lib/python3.6/site-packages/sqlalchemy/sql/operators.py\", line 365, in __eq__\n",
      "    return self.operate(eq, other)\n",
      "  File \"/home/nathan/.conda/envs/tensorflow/lib/python3.6/site-packages/sqlalchemy/orm/attributes.py\", line 210, in operate\n",
      "    return op(self.comparator, *other, **kwargs)\n",
      "  File \"/home/nathan/.conda/envs/tensorflow/lib/python3.6/site-packages/sqlalchemy/orm/relationships.py\", line 1054, in __eq__\n",
      "    \"Can't compare a collection to an object or collection; \"\n",
      "sqlalchemy.exc.InvalidRequestError: Can't compare a collection to an object or collection; use contains() to test for membership.\n",
      "]\n",
      "/home/nathan/.conda/envs/tensorflow/lib/python3.6/site-packages/gym/envs/registration.py:14: PkgResourcesDeprecationWarning: Parameters to load are deprecated.  Call .resolve and .require separately.\n",
      "  result = entry_point.load(False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_get_parent_from_rule: reward-max\n",
      "Session None: 0\n",
      "Training...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-340e975c6502>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'--env-name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CartPole-v1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'--episodes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'10'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0msm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Reinforcement-Learning-Framework/SessionManager.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect_to_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;31m# get the last episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         last_episode = self.db.query(Episode).filter(\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, ident)\u001b[0m\n\u001b[1;32m    934\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[0;32m--> 936\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_on_pk_identity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    937\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m     def _identity_lookup(\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/sqlalchemy/orm/query.py\u001b[0m in \u001b[0;36m_get_impl\u001b[0;34m(self, primary_key_identity, db_load_fn, identity_token)\u001b[0m\n\u001b[1;32m    999\u001b[0m         \u001b[0mmapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_only_full_mapper_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1001\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimary_key_identity\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1002\u001b[0m             raise sa_exc.InvalidRequestError(\n\u001b[1;32m   1003\u001b[0m                 \u001b[0;34m\"Incorrect number of values in identifier to formulate \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    sm.configure(['--env-name', 'CartPole-v1', '--episodes', '10'])\n",
    "    sm.initialize_session()\n",
    "    sm.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'agent_id': 1,\n",
      " 'average_reward': 1.8,\n",
      " 'commit': 'fa33483a0b4bf62868a84ec29abc97b191eb9ada',\n",
      " 'created_at': '2019-02-03 21:48:41.472770',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 100,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 4,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-03 21:48:48.594734'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': None,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 13:32:57.244276',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 100,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 6,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': 'None'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 1.63,\n",
      " 'commit': 'fa33483a0b4bf62868a84ec29abc97b191eb9ada',\n",
      " 'created_at': '2019-02-03 21:48:34.012067',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 100,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 3,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-03 21:48:41.366665'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 4.252,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 14:52:28.233264',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 1000,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 13,\n",
      " 'iteration': 3,\n",
      " 'parent_id': 12,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-05 14:54:15.376128'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 1.835,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 13:33:02.621248',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 100,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 7,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-05 13:41:25.818512'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 4.214,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 14:54:27.126844',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 1000,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 14,\n",
      " 'iteration': 4,\n",
      " 'parent_id': 13,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-05 14:56:18.057443'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 1.97,\n",
      " 'commit': 'fa33483a0b4bf62868a84ec29abc97b191eb9ada',\n",
      " 'created_at': '2019-02-03 21:48:26.141031',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 100,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 2,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-03 21:48:33.901848'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 2.24,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 13:42:07.167299',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 100,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 8,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-05 13:42:16.368777'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 2.27,\n",
      " 'commit': 'fa33483a0b4bf62868a84ec29abc97b191eb9ada',\n",
      " 'created_at': '2019-02-03 21:48:17.921480',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 100,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 1,\n",
      " 'iteration': 0,\n",
      " 'parent_id': None,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-03 21:48:25.997575'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 3.923,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 14:43:26.892085',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 1000,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 11,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-05 14:45:03.757593'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 4.04,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 14:47:59.735522',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 1000,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 12,\n",
      " 'iteration': 2,\n",
      " 'parent_id': 11,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-05 14:49:44.666875'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 2.12,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 14:42:30.030564',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 100,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 9,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-05 14:42:38.991630'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': None,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 14:43:24.283012',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 1000,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 10,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': 'None'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 2.04,\n",
      " 'commit': 'fa33483a0b4bf62868a84ec29abc97b191eb9ada',\n",
      " 'created_at': '2019-02-03 21:49:31.473192',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 100,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 5,\n",
      " 'iteration': 1,\n",
      " 'parent_id': 1,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-03 21:49:40.512359'}\n",
      "{'agent_id': 1,\n",
      " 'average_reward': 4.326,\n",
      " 'commit': 'c2d06e02c0ed22104a17fe05d31410634182c26f',\n",
      " 'created_at': '2019-02-05 14:59:22.420849',\n",
      " 'env_name': 'Test',\n",
      " 'episode_iterations': 1000,\n",
      " 'git_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
      " 'id': 15,\n",
      " 'iteration': 4,\n",
      " 'parent_id': 13,\n",
      " 'save': False,\n",
      " 'updated_at': '2019-02-05 15:01:17.866983'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessions = sm.db.query(Session).all()\n",
    "[pprint(s()) for s in sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = sm.db.query(Session).filter(Session.average_reward != None).order_by(desc(Session.average_reward)).limit(1).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 4,\n",
       " 'agent_id': 1,\n",
       " 'iteration': 1,\n",
       " 'parent_id': 1,\n",
       " 'env_name': 'CartPole-v1',\n",
       " 'commit': 'feef789b3aead6f5694a3038254d1f2bf2bfc377',\n",
       " 'gir_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
       " 'average_reward': 90.26,\n",
       " 'episode_iterations': 100,\n",
       " 'created_at': '2019-02-03 16:24:40.579593',\n",
       " 'updated_at': '2019-02-03 16:25:55.800923'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.db.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61.07, 83.13, 112.35]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[s.average_reward for s in sessions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'agent_id': 1,\n",
       " 'iteration': 0,\n",
       " 'parent_id': None,\n",
       " 'env_name': 'CartPole-v1',\n",
       " 'commit': 'feef789b3aead6f5694a3038254d1f2bf2bfc377',\n",
       " 'gir_url': 'git@github.com:nathanmargaglio/Reinforcement-Learning-Framework.git',\n",
       " 'average_reward': 112.35,\n",
       " 'episode_iterations': 100,\n",
       " 'created_at': '2019-02-03 16:15:36.126489',\n",
       " 'updated_at': '2019-02-03 16:17:58.330766'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session = sessions[-1]\n",
    "session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'config': {},\n",
      " 'created_at': '2019-02-03 21:48:17.852505',\n",
      " 'id': 1,\n",
      " 'name': None,\n",
      " 'save': False,\n",
      " 'summary': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agents = sm.db.query(Agent).all()\n",
    "[pprint(a()) for a in agents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
